# Homework 6: Reflecton

- Due on Saturday, September 21 at 11:59pm
- Weight: 8% of total grade

<br>

**Write**: Reflect on your previous work and how you would adjust to include ethics and inequity components. Total length should be a few paragraphs, no more than one page.

Most databses are built around social and cultural norms as much they are built around effective data systems. Data is holds more power than we perceive, as data leaks and infringements have been some of the more newsworthy incidents in the computational world int he recent years. So information privacy needs to be built into large datasets at multiple levels. For example, sensitive information like hospital records need to be accessible to anyone controlling and inputting data as well as those making decisions based on that data. However, it needs to have enough security checks built in such that the people who have free access to that data cannot abuse their privileges. A fellow colleague's medical information is just as accessible as any other patients' data, and if that information comes to light, there is no guarantee that bias towards a collleague based on medical history can be avoided. Where we can, access to data must be limited by levels. For example colleagues' records might be restricted, and for higher level decision making anonymised data maybe sufficient.

Databases must also be built in a way that accommodates some room for flexibility in structure in the future. For example, Pakistan's national database (NADRA) was not futureproofed by including more than two genders, non-nuclear families, single parents or orphans. While we are unable to anticipate all the changes in the future, change is guaranteed, so smart database designs must always account for guaranteed circumstances. As social norms evolve, people may identify differently, choose to have families outside of legal marriage or not share last names with their partners or children, and data entry needs to accommodate for such evolving climates. While changing the structure of a ginourmous database like NADRA might be incredibly labourious, it is doing a great disservice to the people of their country by not including certain groups of people who do not conform to what was previously considered the norm. 

Data and AI should work for everyone, not just a privileged group of people with money, status, citizenship, or decision-making power. Most decision making in the western world has been traditionally led by white men, with no room for women, gender-diverse people, other races or ethnicities, but their decisions affect the aforementioned minorities and more, usually negatively. The most streamlined method to avoid exclusion to include a diverse group of people in the research,designing and deploying phases. It is normal and somewhat expeceted to have our thinking and design influenced by our lives and backgrounds, so including as many diverse groups as possible will account for flexibility and ensuring that our data systems are inclusive for everyone.

Ethics, AI and data are a dice-game of money, power, and privilege, much like most other things in life. Therefore it is upto those with the money, power, and privilege to make decisions that will not marginalise disenfranchised groups down the line with a tool that likely benefited from their labour to become successful. 